{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Encoder\n",
        "\n",
        "- data 파일 속 초록 값의 embedding 을 계산해, 새로운 열로 추가한 output 파일을 추출\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z_NnMMMc1RtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF3qm0ouIyYq"
      },
      "outputs": [],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "Vtx2Rcd5I4Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Y5_FSxrNI5pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균 풀링 - 주의 마스크(attention_mask)를 올바르게 고려하여 평균 계산\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]  # model_output의 첫 번째 요소에는 모든 토큰 임베딩이 포함됩니다\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
      ],
      "metadata": {
        "id": "awnaqiTdI8II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델과 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained('jhgan/ko-sroberta-multitask')\n",
        "model = AutoModel.from_pretrained('jhgan/ko-sroberta-multitask')\n"
      ],
      "metadata": {
        "id": "SgR1rDLCI9a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 지정 및 타겟값 지정\n",
        "csv_file_path = '/content/drive/MyDrive/23-2 Industrial Engineering/Final_data.csv'  # Update the path as needed\n",
        "target_column = '초록'  # Replace with the actual column name"
      ],
      "metadata": {
        "id": "lXEBtVr7I-oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output_directory = '/content/drive/MyDrive/23-2 Industrial Engineering/output'\n",
        "#os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# 데이터 로드\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 인덱스 섞기\n",
        "shuffled_indices = np.random.permutation(df.index)\n",
        "df_shuffled = df.iloc[shuffled_indices]\n",
        "\n",
        "# 데이터프레임 600 분할\n",
        "num_partitions = 600\n",
        "partition_size = len(df) // num_partitions\n",
        "df_partitions = [df_shuffled[i:i+partition_size] for i in range(0, len(df_shuffled), partition_size)]\n",
        "\n",
        "# 각 데이터프레임을 저장\n",
        "for i, df_partition in enumerate(df_partitions):\n",
        "    globals()[f'df_{i+1}'] = df_partition\n",
        "\n",
        "\n",
        "# 추출 경로 지정\n",
        "sampled_csv_path = '/content/drive/MyDrive/23-2 Industrial Engineering/output_total.csv'  # Update with the desired path\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rqhn_bcyI_yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 수합 프레임 생성\n",
        "merged_df = pd.DataFrame()\n",
        "\n",
        "# 반복\n",
        "for i in range(51, 81):\n",
        "    # 임배딩 값 계산\n",
        "    sample_sentences = list(globals()[f'df_{i}'][target_column])\n",
        "    encoded_inputs = tokenizer(sample_sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_inputs)\n",
        "    sample_embeddings = mean_pooling(model_output, encoded_inputs['attention_mask'])\n",
        "\n",
        "    # 임베딩 값을 NumPy array 로 변환\n",
        "    sample_embeddings_array = sample_embeddings.numpy()\n",
        "\n",
        "    # 새로운 열로 추가\n",
        "    globals()[f'df_{i}']['embeddings'] = sample_embeddings_array.tolist()  # You can rename 'embeddings' to the desired column name\n",
        "\n",
        "    # 데이터 수합 프레임에 추가\n",
        "    merged_df = pd.concat([merged_df, globals()[f'df_{i}']])\n",
        "\n",
        "# CSV 파일 (output) 으로 추출\n",
        "merged_df.to_csv(sampled_csv_path, index=False)\n"
      ],
      "metadata": {
        "id": "rrYCJhvxLnnd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}