{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWP5sH70wr5A"
      },
      "source": [
        "Calculator\n",
        "\n",
        "- encoder로 추출한 output 파일과 input 값의 embedding 값들의 코사인 유사도를 계산\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vkYOOAQITopw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (1.24.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (4.32.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.3)\n",
            "Requirement already satisfied: requests in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: click in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from nltk->sentence-transformers) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qy7MEzuTJ9g"
      },
      "outputs": [],
      "source": [
        "# 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zDmAi0LlTZYv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dts0w5FBVYyd"
      },
      "outputs": [],
      "source": [
        "# 데이터를 NumPy array로 변환하는 함수\n",
        "def parse_and_convert(value):\n",
        "\n",
        "    value = value.strip('[]')\n",
        "    return np.array([float(x) for x in value.split(',')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "EDHJIiVyVJVv"
      },
      "outputs": [],
      "source": [
        "# output 파일 로드\n",
        "csv_file_path = 'output_first.csv'  # Replace with the actual path to your CSV file\n",
        "# csv_file_path = 'output_total.csv'  # Replace with the actual path to your CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# NumPy array로 변환\n",
        "df['embeddings'] = df['embeddings'].apply(parse_and_convert)\n",
        "\n",
        "# 타겟값 지정\n",
        "target_column = 'embeddings'\n",
        "target_data = df[target_column]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40128, 4)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iPZP44KqhGZ"
      },
      "source": [
        "CASE1. 초록을 새로 입력 시 가장 유사한 초록과 그 ipc코드를 반환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_O3_Ic5zke48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f6945743d44fa886cbb6089f9292ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yeppi\\miniconda3\\envs\\gyubin\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yeppi\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08f1f554e3194a7cbaef4a294f8eb318",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcae8ef0b46d45b294d4debd6baca789",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edd4020cdce94396aa1a2751e6eac0d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6bd9307a15642179b67df307830c45c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c2b3924bdc24087bc57e6b09e39b50e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "가장 유사한 초록 \n",
            "-> 단면도 및 정면 뷰\n",
            "\n",
            "유사 ipc코드\n",
            "-> G10K\n"
          ]
        }
      ],
      "source": [
        "# 평균 풀링 - 주의 마스크(attention_mask)를 고려하여 평균 계산\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "# 학습된 모델과 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained('jhgan/ko-sroberta-multitask')\n",
        "model = AutoModel.from_pretrained('jhgan/ko-sroberta-multitask')\n",
        "\n",
        "# 입력 문장\n",
        "input_sentence = input('초록을 입력하세요 : ')\n",
        "\n",
        "# 입력문장 인코딩\n",
        "encoded_input = tokenizer(input_sentence, padding=True, truncation=True, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "input_embedding = mean_pooling(model_output, encoded_input['attention_mask']).numpy()\n",
        "\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "similarity_scores = cosine_similarity(input_embedding, np.stack(target_data.apply(np.array), axis=0))\n",
        "\n",
        "\n",
        "# 가장 유사한 인덱스 추출\n",
        "most_similar_row_index = np.argmax(similarity_scores)\n",
        "result_1 = df.loc[most_similar_row_index, '초록']\n",
        "result_2 = df.loc[most_similar_row_index, 'ipc코드']\n",
        "\n",
        "# 결과 도출\n",
        "print(\"\\n가장 유사한 초록 \\n->\",result_1)\n",
        "print(\"\\n유사 ipc코드\\n->\",result_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDVnpBdbyc-B"
      },
      "source": [
        "CASE2. ipc 코드 맞출 확률 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GW8_75n8uw36"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "# 확률계산 함수 설정\n",
        "def calculate_matching_ipc_probability(df, tokenizer, model, num):\n",
        "    matching_count = 0\n",
        "    big_count = 0\n",
        "    total_count = 0\n",
        "    \n",
        "    A = 0\n",
        "    B = 0\n",
        "    C = 0\n",
        "    D = 0\n",
        "    E = 0\n",
        "    F = 0\n",
        "    G = 0\n",
        "    \n",
        "    a = 0\n",
        "    b = 0\n",
        "    c = 0\n",
        "    d = 0\n",
        "    e = 0\n",
        "    f = 0\n",
        "    g = 0\n",
        "    \n",
        "    a_same = 0\n",
        "    b_same = 0\n",
        "    c_same = 0\n",
        "    d_same = 0\n",
        "    e_same = 0\n",
        "    f_same = 0\n",
        "    g_same = 0\n",
        "    \n",
        "    \n",
        "    \n",
        "    for _ in tqdm(range(num)):\n",
        "        # df 내 100개 데이터 랜덤 추출\n",
        "\n",
        "        random_index = np.random.randint(len(df)-1)\n",
        "        random_row = df.iloc[random_index]\n",
        "        df = df.drop(random_index)\n",
        "        df = df.reset_index(drop = True)\n",
        "        \n",
        "        # 입력 문장\n",
        "        input_sentence = random_row['초록']\n",
        "\n",
        "        # 입력 문장 인코딩\n",
        "        encoded_input = tokenizer(input_sentence, padding=True, truncation=True, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            model_output = model(**encoded_input)\n",
        "        input_embedding = mean_pooling(model_output, encoded_input['attention_mask']).numpy()\n",
        "\n",
        "        # 코사인 유사도 계산\n",
        "        similarity_scores = cosine_similarity(input_embedding, np.stack(df['embeddings'].to_numpy(), axis=0))\n",
        "\n",
        "        # 가장 유사한 인덱스 추출\n",
        "        most_similar_row_index = np.argmax(similarity_scores)\n",
        "        most_similar_row = df.iloc[most_similar_row_index]\n",
        "\n",
        "        # ipc코드 매칭 여부\n",
        "        ran_IPC = random_row['ipc코드']\n",
        "        sim_IPC = most_similar_row['ipc코드']\n",
        "        \n",
        "        if ran_IPC == sim_IPC:\n",
        "            matching_count += 1\n",
        "        if ran_IPC[0] == sim_IPC[0]:\n",
        "            big_count += 1\n",
        "        \n",
        "        if ran_IPC[0] == 'A':\n",
        "            A += 1\n",
        "            if sim_IPC[0] == 'A':\n",
        "                a += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    a_same += 1\n",
        "        if ran_IPC[0] == 'B':\n",
        "            B += 1\n",
        "            if sim_IPC[0] == 'B':\n",
        "                b += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    b_same += 1                \n",
        "        if ran_IPC[0] == 'C':\n",
        "            C += 1\n",
        "            if sim_IPC[0] == 'C':\n",
        "                c += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    c_same += 1                \n",
        "        if ran_IPC[0] == 'D':\n",
        "            D += 1\n",
        "            if sim_IPC[0] == 'D':\n",
        "                d += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    d_same += 1                \n",
        "        if ran_IPC[0] == 'E':\n",
        "            E += 1\n",
        "            if sim_IPC[0] == 'E':\n",
        "                e += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    e_same += 1                \n",
        "        if ran_IPC[0] == 'F':\n",
        "            F += 1\n",
        "            if sim_IPC[0] == 'F':\n",
        "                f += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    f_same += 1                \n",
        "        if ran_IPC[0] == 'G':\n",
        "            G += 1\n",
        "            if sim_IPC[0] == 'G':\n",
        "                g += 1\n",
        "                if ran_IPC == sim_IPC:\n",
        "                    g_same += 1                \n",
        "                                                                                                   \n",
        "        \n",
        "\n",
        "        total_count += 1\n",
        "        # 복원\n",
        "        df = df.append(random_row)\n",
        "    \n",
        "    big_probability = big_count / total_count\n",
        "    matching_probability = matching_count / total_count\n",
        "    last = [a/A, b/B, c/C, d/D, e/E, f/F, g/G]\n",
        "    semi = [a_same/a, b_same/b, c_same/c, d_same/d, e_same/e, f_same/f, g_same/g]\n",
        "    print('*' * 30)\n",
        "    print(f\"ipc코드 4자리 맞출 확률 : {matching_probability*100}'%' \")\n",
        "    print(f\"ipc코드 대분류 맞출 확률 : {big_probability*100}'%' \")\n",
        "    print(f\"소분류 A 맞출 확률 : {last[0]*100}'%' \")\n",
        "    print(f\"소분류 B 맞출 확률 : {last[1]*100}'%' \")\n",
        "    print(f\"소분류 C 맞출 확률 : {last[2]*100}'%' \")\n",
        "    print(f\"소분류 D 맞출 확률 : {last[3]*100}'%' \")\n",
        "    print(f\"소분류 E 맞출 확률 : {last[4]*100}'%' \")\n",
        "    print(f\"소분류 F 맞출 확률 : {last[5]*100}'%' \")\n",
        "    print(f\"소분류 F 맞출 확률 : {last[6]*100}'%' \")\n",
        "    print('*' * 30)\n",
        "    print(f\"4자리 맞출 확률 : {(a_same + b_same + c_same + d_same + e_same + f_same + g_same)/(a+b+c+d+e+f+g)}\")\n",
        "    print(f\"A 4자리 맞출 확률 : {semi[0]*100}'%' \")\n",
        "    print(f\"B 4자리 맞출 확률 : {semi[1]*100}'%' \")\n",
        "    print(f\"C 4자리 맞출 확률 : {semi[2]*100}'%' \")\n",
        "    print(f\"D 4자리 맞출 확률 : {semi[3]*100}'%' \")\n",
        "    print(f\"E 4자리 맞출 확률 : {semi[4]*100}'%' \")\n",
        "    print(f\"F 4자리 맞출 확률 : {semi[5]*100}'%' \")\n",
        "    print(f\"F 4자리 맞출 확률 : {semi[6]*100}'%' \")    \n",
        "    \n",
        "    return matching_probability, big_probability, last\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 174/1000 [01:11<05:36,  2.45it/s]"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "seed = 0\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(seed)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 결과 도출\n",
        "matching_probability, big_probability, last = calculate_matching_ipc_probability(df.copy(), tokenizer, model, 1000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
